{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db38f2e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of paramerters in networks is 11690097  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from util.util import lr_scheduler\n",
    "from datasets.reconstructed_ES_imagenet import ESImagenet2D_Dataset\n",
    "#from datasets.es_imagenet import ESImagenet_Dataset\n",
    "\n",
    "from LIAFnet.LIAFResNet import *\n",
    "\n",
    "import torch.distributed as dist\n",
    "import torch.nn as nn\n",
    "import argparse, pickle, torch, time, os,sys\n",
    "from importlib import import_module\n",
    "from tensorboardX import SummaryWriter\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "\n",
    "#from torchvision.models import resnet18\n",
    "\n",
    "##################### Step1. Env Preparation #####################\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "   \n",
    "##################### Step2. load in dataset #####################\n",
    "modules = import_module('LIAFnet.LIAFResNet_18')\n",
    "config  = modules.Config()\n",
    "workpath = os.path.abspath(os.getcwd())\n",
    "num_epochs = config.num_epochs\n",
    "batch_size = config.batch_size\n",
    "timeWindows = config.timeWindows\n",
    "config.cfgCnn = [1,64,7]\n",
    "\n",
    "\n",
    "epoch = 0\n",
    "best_acc = 0  # best test accuracy\n",
    "start_epoch = 0  # start from epoch 0 or last checkpoint epoch\n",
    "training_iter = 0\n",
    "start_epoch = 0\n",
    "acc_record = list([])\n",
    "loss_train_record = list([])\n",
    "loss_test_record = list([])\n",
    "\n",
    "batch_size = 12\n",
    "\n",
    "\n",
    "test_dataset = ESImagenet2D_Dataset(mode='test',data_set_path='/data/ES-imagenet-0.18/')\n",
    "#test_dataset = ESImagenet_Dataset(mode='test',data_set_path='../data/Validation_Set/')\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=True, num_workers=2,pin_memory=True)\n",
    "\n",
    "\n",
    "##################### Step3. establish module #####################\n",
    "#modules = import_module('LIAFnet.LIAFResNet_18')\n",
    "#config  = modules.Config()\n",
    "\n",
    "cnn = LIAFResNet(config)\n",
    "print(\"Total number of paramerters in networks is {}  \".format(sum(x.numel() for x in cnn.parameters())))\n",
    "cnn.to(device)\n",
    "pretrain_path = '../pretrained_model/ResNet18_2D_gray_acc40.pth'\n",
    "checkpoint = torch.load(pretrain_path, map_location=torch.device('cpu'))\n",
    "cnn.load_state_dict(checkpoint['state'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1bf4c593",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start validation\n",
      "8.333333333333334 0 / 4156.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method _MultiProcessingDataLoaderIter.__del__ of <torch.utils.data.dataloader._MultiProcessingDataLoaderIter object at 0x7f6a26497048>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lyh/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/lyh/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/home/lyh/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py\", line 134, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <bound method _MultiProcessingDataLoaderIter.__del__ of <torch.utils.data.dataloader._MultiProcessingDataLoaderIter object at 0x7f6a26497048>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lyh/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/lyh/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/home/lyh/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py\", line 134, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39.43894389438944 100 / 4156.75\n",
      "39.8424543946932 200 / 4156.75\n",
      "40.33776301218162 300 / 4156.75\n",
      "40.586034912718205 400 / 4156.75\n",
      "40.53559547571523 500 / 4156.75\n",
      "40.68219633943428 600 / 4156.75\n",
      "40.75130765572991 700 / 4156.75\n",
      "40.70952975447357 800 / 4156.75\n",
      "40.42730299667036 900 / 4156.75\n",
      "40.3013653013653 1000 / 4156.75\n",
      "40.213442325158944 1100 / 4156.75\n",
      "40.195670274771025 1200 / 4156.75\n",
      "40.244683576735845 1300 / 4156.75\n",
      "40.251011182488696 1400 / 4156.75\n",
      "40.18432156340218 1500 / 4156.75\n",
      "40.02706641682282 1600 / 4156.75\n",
      "40.06466784244562 1700 / 4156.75\n",
      "39.96853599851934 1800 / 4156.75\n",
      "39.94388918113274 1900 / 4156.75\n",
      "39.82175578877228 2000 / 4156.75\n",
      "39.778676820561635 2100 / 4156.75\n",
      "39.73951234287445 2200 / 4156.75\n",
      "39.7798058815008 2300 / 4156.75\n",
      "39.90004164931278 2400 / 4156.75\n",
      "39.777422364387576 2500 / 4156.75\n",
      "39.74112520825324 2600 / 4156.75\n",
      "39.74762433666543 2700 / 4156.75\n",
      "39.76853504700702 2800 / 4156.75\n",
      "39.762150982419854 2900 / 4156.75\n",
      "39.75063867599689 3000 / 4156.75\n",
      "39.70493389229281 3100 / 4156.75\n",
      "39.77923565552432 3200 / 4156.75\n",
      "39.841462183176816 3300 / 4156.75\n",
      "39.958835636577476 3400 / 4156.75\n",
      "39.99333523755118 3500 / 4156.75\n",
      "39.96806442654818 3600 / 4156.75\n",
      "39.99144375394037 3700 / 4156.75\n",
      "39.989476453564855 3800 / 4156.75\n",
      "40.041015124327096 3900 / 4156.75\n",
      "40.02124468882779 4000 / 4156.75\n",
      "39.99024628139478 4100 / 4156.75\n",
      "acc: 40.00040102662817\n"
     ]
    }
   ],
   "source": [
    "################step4. training and validation ################\n",
    "\n",
    "def val(cnn,test_loader,test_dataset,batch_size,epoch):\n",
    "    cnn.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    predicted = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(test_loader):\n",
    "            if ((batch_idx+1)<=len(test_dataset)//batch_size):\n",
    "                try:\n",
    "                    #print(\"inside\")\n",
    "                    targets=targets.view(batch_size)#tiny bug\n",
    "                    outputs = cnn(inputs.to(device))#.type(LIAF.dtype))\n",
    "                    _ , predicted = outputs.cpu().max(1)\n",
    "                    total += float(targets.size(0))\n",
    "                    correct += float(predicted.eq(targets).sum())\n",
    "                    \n",
    "                    if batch_idx%100 == 0:\n",
    "                        acc = 100. * float(correct) / float(total)\n",
    "                        print(acc, batch_idx,'/',len(test_dataset)/batch_size)\n",
    "        \n",
    "                except:\n",
    "                    print('sth. wrong')\n",
    "                    print('val_error:',batch_idx, end='')\n",
    "                    print('taret_size:',targets.size())\n",
    "               \n",
    "                #print(batch_idx,'/',len(test_dataset)/batch_size)\n",
    "\n",
    "        acc = 100. * float(correct) / float(total)\n",
    "    return acc\n",
    "\n",
    "print('start validation')\n",
    "acc = val(cnn,test_loader,test_dataset,batch_size,epoch=-1)\n",
    "print('acc:',acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c871b91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "state = {'state': cnn.module.state_dict()}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
