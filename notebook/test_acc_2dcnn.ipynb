{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db38f2e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of paramerters in networks is 11690097  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from util.util import lr_scheduler\n",
    "from datasets.reconstructed_ES_imagenet import ESImagenet2D_Dataset\n",
    "#from datasets.es_imagenet import ESImagenet_Dataset\n",
    "\n",
    "from LIAFnet.LIAFResNet import *\n",
    "\n",
    "import torch.distributed as dist\n",
    "import torch.nn as nn\n",
    "import argparse, pickle, torch, time, os,sys\n",
    "from importlib import import_module\n",
    "from tensorboardX import SummaryWriter\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "\n",
    "#from torchvision.models import resnet18\n",
    "\n",
    "##################### Step1. Env Preparation #####################\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "   \n",
    "##################### Step2. load in dataset #####################\n",
    "modules = import_module('LIAFnet.LIAFResNet_18')\n",
    "config  = modules.Config()\n",
    "workpath = os.path.abspath(os.getcwd())\n",
    "num_epochs = config.num_epochs\n",
    "batch_size = config.batch_size\n",
    "timeWindows = config.timeWindows\n",
    "config.cfgCnn = [1,64,7]\n",
    "\n",
    "\n",
    "epoch = 0\n",
    "best_acc = 0  # best test accuracy\n",
    "start_epoch = 0  # start from epoch 0 or last checkpoint epoch\n",
    "training_iter = 0\n",
    "start_epoch = 0\n",
    "acc_record = list([])\n",
    "loss_train_record = list([])\n",
    "loss_test_record = list([])\n",
    "\n",
    "batch_size = 4\n",
    "\n",
    "\n",
    "test_dataset = ESImagenet2D_Dataset(mode='test',data_set_path='/data/ES-imagenet-0.18/')\n",
    "#test_dataset = ESImagenet_Dataset(mode='test',data_set_path='../data/Validation_Set/')\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=True, num_workers=2,pin_memory=True)\n",
    "\n",
    "\n",
    "##################### Step3. establish module #####################\n",
    "#modules = import_module('LIAFnet.LIAFResNet_18')\n",
    "#config  = modules.Config()\n",
    "\n",
    "cnn = LIAFResNet(config)\n",
    "print(\"Total number of paramerters in networks is {}  \".format(sum(x.numel() for x in cnn.parameters())))\n",
    "cnn = LIAFResNet(config)\n",
    "cnn.to(device)\n",
    "pretrain_path = '../pretrained_model/42-Copy1.pkl'\n",
    "checkpoint = torch.load(pretrain_path, map_location=torch.device('cpu'))\n",
    "cnn.load_state_dict(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1bf4c593",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start validation\n",
      "0.0 0 / 12470.25\n",
      "0.0 100 / 12470.25\n",
      "0.0 200 / 12470.25\n",
      "0.0 300 / 12470.25\n",
      "0.0 400 / 12470.25\n",
      "0.0998003992015968 500 / 12470.25\n",
      "0.08319467554076539 600 / 12470.25\n",
      "0.1783166904422254 700 / 12470.25\n",
      "0.1560549313358302 800 / 12470.25\n",
      "0.13873473917869034 900 / 12470.25\n",
      "0.12487512487512488 1000 / 12470.25\n",
      "0.11353315168029064 1100 / 12470.25\n",
      "0.10407993338884262 1200 / 12470.25\n",
      "0.09607993850883935 1300 / 12470.25\n",
      "0.08922198429693076 1400 / 12470.25\n",
      "0.0832778147901399 1500 / 12470.25\n",
      "0.07807620237351655 1600 / 12470.25\n",
      "0.08818342151675485 1700 / 12470.25\n",
      "0.0832870627429206 1800 / 12470.25\n",
      "0.0920568122041031 1900 / 12470.25\n",
      "0.08745627186406797 2000 / 12470.25\n",
      "0.08329366968110423 2100 / 12470.25\n",
      "0.07950931394820536 2200 / 12470.25\n",
      "0.0869187309865276 2300 / 12470.25\n",
      "0.0937109537692628 2400 / 12470.25\n",
      "0.0899640143942423 2500 / 12470.25\n",
      "0.08650519031141868 2600 / 12470.25\n",
      "0.08330248056275454 2700 / 12470.25\n",
      "0.08032845412352731 2800 / 12470.25\n",
      "0.07755946225439504 2900 / 12470.25\n",
      "0.08330556481172942 3000 / 12470.25\n",
      "0.08061915511125443 3100 / 12470.25\n",
      "0.07810059356451109 3200 / 12470.25\n",
      "0.0757346258709482 3300 / 12470.25\n",
      "0.07350779182593355 3400 / 12470.25\n",
      "0.07854898600399886 3500 / 12470.25\n",
      "0.07636767564565398 3600 / 12470.25\n",
      "0.07430424209673062 3700 / 12470.25\n",
      "0.07234938174164693 3800 / 12470.25\n",
      "0.07690335811330429 3900 / 12470.25\n",
      "0.07498125468632842 4000 / 12470.25\n",
      "0.07315288953913679 4100 / 12470.25\n",
      "0.0773625327303023 4200 / 12470.25\n",
      "0.07556382236689142 4300 / 12470.25\n",
      "0.07384685298795728 4400 / 12470.25\n",
      "0.07220617640524328 4500 / 12470.25\n",
      "0.07063681808302542 4600 / 12470.25\n",
      "0.06913422676026378 4700 / 12470.25\n",
      "0.0676942303686732 4800 / 12470.25\n",
      "0.07141399714344011 4900 / 12470.25\n",
      "0.06998600279944012 5000 / 12470.25\n",
      "0.06861399725544011 5100 / 12470.25\n",
      "0.06729475100942127 5200 / 12470.25\n",
      "0.07074136955291455 5300 / 12470.25\n",
      "0.0694315867431957 5400 / 12470.25\n",
      "0.06816942374113798 5500 / 12470.25\n",
      "0.06695232994108195 5600 / 12470.25\n",
      "0.06577793369584284 5700 / 12470.25\n",
      "0.06895362868470953 5800 / 12470.25\n",
      "0.07202169123877308 5900 / 12470.25\n",
      "0.07915347442092985 6000 / 12470.25\n",
      "0.081953778069169 6100 / 12470.25\n",
      "0.08063215610385421 6200 / 12470.25\n",
      "0.08332010791937787 6300 / 12470.25\n",
      "0.08201843461959069 6400 / 12470.25\n",
      "0.08460236886632826 6500 / 12470.25\n",
      "0.08332070898348735 6600 / 12470.25\n",
      "0.08953887479480674 6700 / 12470.25\n",
      "0.08822232024702249 6800 / 12470.25\n",
      "0.0869439211708448 6900 / 12470.25\n",
      "0.0857020425653478 7000 / 12470.25\n",
      "0.08449514152936206 7100 / 12470.25\n",
      "0.08332176086654632 7200 / 12470.25\n",
      "0.08218052321599781 7300 / 12470.25\n",
      "0.08107012565869477 7400 / 12470.25\n",
      "0.07998933475536595 7500 / 12470.25\n",
      "0.07893698197605578 7600 / 12470.25\n",
      "0.07791195948578107 7700 / 12470.25\n",
      "0.07691321625432637 7800 / 12470.25\n",
      "0.07593975446146058 7900 / 12470.25\n",
      "0.07499062617172854 8000 / 12470.25\n",
      "0.074064930255524 8100 / 12470.25\n",
      "0.0731618095354225 8200 / 12470.25\n",
      "0.07228044813877846 8300 / 12470.25\n",
      "0.07439590524937507 8400 / 12470.25\n",
      "0.07352076226326315 8500 / 12470.25\n",
      "0.07266596907336356 8600 / 12470.25\n",
      "0.07183082404321342 8700 / 12470.25\n",
      "0.07385524372230429 8800 / 12470.25\n",
      "0.07583417593528817 8900 / 12470.25\n",
      "0.07499166759248972 9000 / 12470.25\n",
      "0.07416767388199098 9100 / 12470.25\n",
      "0.07607868709922834 9200 / 12470.25\n",
      "0.07526072465326308 9300 / 12470.25\n",
      "0.07446016381236038 9400 / 12470.25\n",
      "0.0763077570782023 9500 / 12470.25\n",
      "0.07551296739922925 9600 / 12470.25\n",
      "0.07473456344706732 9700 / 12470.25\n",
      "0.07397204366901336 9800 / 12470.25\n",
      "0.07322492677507322 9900 / 12470.25\n",
      "0.074992500749925 10000 / 12470.25\n",
      "0.07672507672507672 10100 / 12470.25\n",
      "0.07842368395255367 10200 / 12470.25\n",
      "0.080089311717309 10300 / 12470.25\n",
      "0.07931929622151716 10400 / 12470.25\n",
      "0.07856394629082944 10500 / 12470.25\n",
      "0.07782284690123573 10600 / 12470.25\n",
      "0.07943182880104663 10700 / 12470.25\n",
      "0.08101101749837979 10800 / 12470.25\n",
      "0.08026786533345565 10900 / 12470.25\n",
      "0.07953822379783657 11000 / 12470.25\n",
      "0.08107377713719485 11100 / 12470.25\n",
      "0.08258191232925631 11200 / 12470.25\n",
      "0.08185116361383948 11300 / 12470.25\n",
      "0.08332602403297956 11400 / 12470.25\n",
      "0.08260151291192071 11500 / 12470.25\n",
      "0.08619946556331351 11600 / 12470.25\n",
      "0.0854627809588924 11700 / 12470.25\n",
      "0.08685704601304974 11800 / 12470.25\n",
      "0.0861272162003193 11900 / 12470.25\n",
      "0.08540954920423298 12000 / 12470.25\n",
      "0.08470374349227336 12100 / 12470.25\n",
      "0.08605851979345955 12200 / 12470.25\n",
      "0.08739126900252012 12300 / 12470.25\n",
      "0.0866865575356826 12400 / 12470.25\n",
      "acc: 0.08620689655172414\n"
     ]
    }
   ],
   "source": [
    "################step4. training and validation ################\n",
    "\n",
    "def val(cnn,test_loader,test_dataset,batch_size,epoch):\n",
    "    cnn.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    predicted = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(test_loader):\n",
    "            if ((batch_idx+1)<=len(test_dataset)//batch_size):\n",
    "                try:\n",
    "                    #print(\"inside\")\n",
    "                    targets=targets.view(batch_size)#tiny bug\n",
    "                    outputs = cnn(inputs.to(device))#.type(LIAF.dtype))\n",
    "                    _ , predicted = outputs.cpu().max(1)\n",
    "                    total += float(targets.size(0))\n",
    "                    correct += float(predicted.eq(targets).sum())\n",
    "                    \n",
    "                    if batch_idx%100 == 0:\n",
    "                        acc = 100. * float(correct) / float(total)\n",
    "                        print(acc, batch_idx,'/',len(test_dataset)/batch_size)\n",
    "        \n",
    "                except:\n",
    "                    print('sth. wrong')\n",
    "                    print('val_error:',batch_idx, end='')\n",
    "                    print('taret_size:',targets.size())\n",
    "               \n",
    "                #print(batch_idx,'/',len(test_dataset)/batch_size)\n",
    "\n",
    "        acc = 100. * float(correct) / float(total)\n",
    "    return acc\n",
    "\n",
    "print('start validation')\n",
    "acc = val(cnn,test_loader,test_dataset,batch_size,epoch=-1)\n",
    "print('acc:',acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c871b91c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
